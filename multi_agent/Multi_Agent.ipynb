{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import supersuit as ss\n",
    "from pettingzoo.mpe import simple_adversary_v2\n",
    "\n",
    "# Creating simple_adversary_v2 parallel env\n",
    "orig_env = simple_adversary_v2.parallel_env()\n",
    "action_spaces = orig_env.action_spaces\n",
    "env = ss.pad_observations_v0(orig_env)\n",
    "env = ss.pettingzoo_env_to_vec_env_v0(env)\n",
    "\n",
    "num_envs = 2\n",
    "env = ss.concat_vec_envs_v0(env, num_envs, num_cpus=4, base_class=\"gym\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "observations, rewards, dones, infos = env.step([env.action_space.sample() for i in range(env.num_envs)])\n",
    "# TODO: implement training loop\n",
    "# TODO: implement model with just one policy per agent\n",
    "# TODO: implement policy ensemble"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_agents = orig_env.max_num_agents\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_space_size = env.action_space.n\n",
    "\n",
    "print(\"Num of agents: \", num_agents)\n",
    "print(\"State Size: \", state_size)\n",
    "print(\"Action Space Size: \", action_space_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from agent import MultiAgentActorCritic\n",
    "agent = MultiAgentActorCritic(num_agents, num_envs, state_size, action_space_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_episodes = 100\n",
    "train_mode = True\n",
    "max_t = 26\n",
    "\n",
    "scores_window = deque(maxlen=100)  # last 100 scores\n",
    "scores = []\n",
    "\n",
    "for i_episode in range(1, n_episodes + 1):\n",
    "    states = env.reset()\n",
    "\n",
    "    score = np.zeros((num_agents * num_envs, ))\n",
    "    for t in range(max_t):\n",
    "        actions = agent.act(states)\n",
    "        try:\n",
    "            next_states, rewards, dones, infos = env.step(actions)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "\n",
    "        if train_mode:\n",
    "            agent.step(states, actions, rewards, next_states, dones)\n",
    "        states = next_states\n",
    "        score += rewards\n",
    "        if np.any(dones):\n",
    "            break\n",
    "\n",
    "    score = score.reshape((num_envs, num_agents)).mean(axis=0)\n",
    "    scores_window.append(score)  # save most recent score\n",
    "    scores.append(score)  # save most recent score\n",
    "    mean_score_window = np.mean(scores_window, axis=0)\n",
    "    print(\n",
    "        f\"\\rEpisode {i_episode}\\tAverage Score: {mean_score_window}\",\n",
    "        end=\"\",\n",
    "    )\n",
    "    if i_episode % 5 == 0:\n",
    "        print(f\"\\rEpisode {i_episode}\\tAverage Score: {mean_score_window}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}